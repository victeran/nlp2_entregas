{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d36ed39-2cea-4efc-aacf-6388c0209c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/posgrado/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Importación de librerías\n",
    "# ===========================\n",
    "import fitz  # Para manipular archivos PDF\n",
    "from pinecone import Pinecone, ServerlessSpec  # Para gestión de vectores en Pinecone\n",
    "from openai import OpenAI  # Cliente OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Para dividir texto en chunks\n",
    "from langchain.docstore.document import Document  # Para manejar documentos\n",
    "from pdfminer.high_level import extract_text  # Para extraer texto de PDFs\n",
    "from sentence_transformers import SentenceTransformer  # Para obtener embeddings con modelos locales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24b68bd8-a66c-4d99-8166-d8766c84ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Configuración y claves API\n",
    "# ===========================\n",
    "PINECONE_API_KEY = \"\"\n",
    "PINECONE_ENV = \"gcp-starter\"\n",
    "PINECONE_INDEX = \"cv-index\"\n",
    "OPENAI_API_KEY = \"\"\n",
    "GROQ_API_KEY =\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b70fd7c-237c-4a5f-9f02-221f9599f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Inicialización de clientes\n",
    "# ===========================\n",
    "\n",
    "# Cliente OpenAI para llamadas API\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Cliente Pinecone para gestión de vectores\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9362f1d0-5d81-4f49-aa18-c944740c958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Configuración del índice en Pinecone\n",
    "# ===========================\n",
    "\n",
    "# Verificar si el índice existe; si no, crearlo\n",
    "if PINECONE_INDEX not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=PINECONE_INDEX,\n",
    "        dimension=384,  # Dimensión de los vectores (se define por el modelo utilizado para generar embeddings)\n",
    "        metric='euclidean',  # Métrica para comparación\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',  \n",
    "            region='us-east-1'  \n",
    "        )\n",
    "    )\n",
    "\n",
    "# Conectar al índice\n",
    "index = pc.Index(PINECONE_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e653837e-485a-4f24-9383-9f5e40789aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Función para extraer texto de PDF usando 'fitz'\n",
    "# ===========================\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e0901d-26db-428f-a7a3-332259defad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Función para obtener embeddings usando OpenAI\n",
    "# ===========================\n",
    "def get_embedding(texto):\n",
    "    response = client.embeddings.create(\n",
    "        input=[texto],\n",
    "        model=\"text-embedding-3-small\"  # Modelo de embedding (puede variar)\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d607aa2a-1597-4750-aeac-c7bb20908480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Función para cargar y extraer texto de PDF con 'pdfminer'\n",
    "# ===========================\n",
    "def extract_text_from_pdf(file_path):\n",
    "    return extract_text(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18c24052-5f6d-4654-9a5c-1bcd11e465b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Función para crear un objeto Document de LangChain\n",
    "# ===========================\n",
    "def create_document(text, metadata=None):\n",
    "    if metadata is None:\n",
    "        metadata = {}\n",
    "    return Document(page_content=text, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4962ee45-58d9-4d14-9161-2ab59a8cb194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Función para dividir texto en chunks\n",
    "# ===========================\n",
    "def chunk_text(document, chunk_size=1000, chunk_overlap=200):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return splitter.split_documents([document])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f44dcc8c-4406-4eaa-8be9-719db7073ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "Victoria Terán\n",
      "\n",
      "DATA SCIENTIST\n",
      "\n",
      "Contacto\n",
      "\n",
      "Experiencia\n",
      "\n",
      "mvictoriateran@gmail.com\n",
      "\n",
      "Analista Sr de Ries\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Registros  contables  y  procesos  afines  a  la  concilicación\n",
      "\n",
      "bancaria;  control  y  reposición  \n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Uso del proceso completo\n",
    "# ===========================\n",
    "\n",
    "pdf_path = \"CV_VictoriaTeran.pdf\"\n",
    "\n",
    "# Extraer todo el texto del PDF\n",
    "full_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Crear un objeto Document con el texto completo y metadata\n",
    "doc = create_document(full_text, metadata={\"source\": pdf_path})\n",
    "\n",
    "# Dividir el texto en chunks \n",
    "chunks = chunk_text(doc)\n",
    "\n",
    "# Mostrar algunos ejemplos de los chunks generados\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(chunk.page_content[:100])  # Muestra los primeros 100 caracteres del chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3030be73-e23c-4ce8-8c86-5cfef00c5c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Obtenemos los embeddings con modelo local\n",
    "# ===========================\n",
    "\n",
    "# Cargar modelo de embeddings local\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  \n",
    "\n",
    "# Función para obtener embedding usando modelo local\n",
    "def get_embedding(text):\n",
    "    return embedding_model.encode(text).tolist()\n",
    "\n",
    "# Crear lista de textos desde los chunks\n",
    "text_chunks = [chunk.page_content for chunk in chunks]\n",
    "\n",
    "# Crear vectores con embeddings y metadatos\n",
    "vectors = []\n",
    "for i, chunk in enumerate(text_chunks):\n",
    "    vector = {\n",
    "        \"id\": f\"chunk-{i}\",\n",
    "        \"values\": get_embedding(chunk),\n",
    "        \"metadata\": {\n",
    "            \"text\": chunk\n",
    "        }\n",
    "    }\n",
    "    vectors.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "475a9c89-d955-4bbc-83d1-153c1d6b79ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'euclidean',\n",
      " 'namespaces': {'': {'vector_count': 2}},\n",
      " 'total_vector_count': 2,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Se envian los embeddings a pinecone\n",
    "# ===========================\n",
    "\n",
    "index.upsert(vectors=vectors)\n",
    "print(index.describe_index_stats())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
