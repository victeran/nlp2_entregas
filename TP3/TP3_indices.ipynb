{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d36ed39-2cea-4efc-aacf-6388c0209c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/posgrado/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Importación de librerías\n",
    "# ===========================\n",
    "import fitz  # Para manipular archivos PDF\n",
    "from pinecone import Pinecone, ServerlessSpec  # Para gestión de vectores en Pinecone\n",
    "from openai import OpenAI  # Cliente OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Para dividir texto en chunks\n",
    "from langchain.docstore.document import Document  # Para manejar documentos\n",
    "from pdfminer.high_level import extract_text  # Para extraer texto de PDFs\n",
    "from sentence_transformers import SentenceTransformer  # Para obtener embeddings con modelos locales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24b68bd8-a66c-4d99-8166-d8766c84ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Configuración y claves API\n",
    "# ===========================\n",
    "PINECONE_API_KEY = \"\"\n",
    "PINECONE_ENV = \"gcp-starter\"\n",
    "OPENAI_API_KEY = \"\"\n",
    "GROQ_API_KEY =\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b70fd7c-237c-4a5f-9f02-221f9599f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Inicialización de clientes\n",
    "# ===========================\n",
    "\n",
    "# Cliente OpenAI para llamadas API\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Cliente Pinecone para gestión de vectores\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9a9ac-ad09-4d4c-ae18-7a665dcd1aab",
   "metadata": {},
   "source": [
    "# CV LARA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797d5aee-28af-49b3-9368-4aac9ca263f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_INDEX = \"cv-lara-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9362f1d0-5d81-4f49-aa18-c944740c958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Configuración del índice en Pinecone\n",
    "# ===========================\n",
    "\n",
    "# Verificar si el índice existe; si no, crearlo\n",
    "if PINECONE_INDEX not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=PINECONE_INDEX,\n",
    "        dimension=384,  # Dimensión de los vectores (se define por el modelo utilizado para generar embeddings)\n",
    "        metric='euclidean',  # Métrica para comparación\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',  \n",
    "            region='us-east-1'  \n",
    "        )\n",
    "    )\n",
    "\n",
    "# Conectar al índice\n",
    "index = pc.Index(PINECONE_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e653837e-485a-4f24-9383-9f5e40789aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Función para extraer texto de PDF usando 'fitz'\n",
    "# ===========================\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e0901d-26db-428f-a7a3-332259defad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Función para obtener embeddings usando OpenAI\n",
    "# ===========================\n",
    "def get_embedding(texto):\n",
    "    response = client.embeddings.create(\n",
    "        input=[texto],\n",
    "        model=\"text-embedding-3-small\"  # Modelo de embedding (puede variar)\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d607aa2a-1597-4750-aeac-c7bb20908480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Función para cargar y extraer texto de PDF con 'pdfminer'\n",
    "# ===========================\n",
    "def extract_text_from_pdf(file_path):\n",
    "    return extract_text(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c24052-5f6d-4654-9a5c-1bcd11e465b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Función para crear un objeto Document de LangChain\n",
    "# ===========================\n",
    "def create_document(text, metadata=None):\n",
    "    if metadata is None:\n",
    "        metadata = {}\n",
    "    return Document(page_content=text, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4962ee45-58d9-4d14-9161-2ab59a8cb194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Función para dividir texto en chunks\n",
    "# ===========================\n",
    "def chunk_text(document, chunk_size=1000, chunk_overlap=200):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return splitter.split_documents([document])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f44dcc8c-4406-4eaa-8be9-719db7073ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "DATOS PERSONALES \n",
      "Lara Rosenberg  \n",
      "Buenos Aires, Argentina  \n",
      "Email: lararosenberg21@gmail.com  \n",
      "Telé\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Credit Risk Modeling Sr Analyst (Marzo 2023 - Marzo 2024)   \n",
      "- Desarrollo de modelos de score de rie\n",
      "\n",
      "--- Chunk 3 ---\n",
      "BANCO PATAGONIA  (Septiembre 2019 - Marzo 2020) \n",
      "Analista de Riesgos Financieros     \n",
      "- Evaluación d\n",
      "\n",
      "--- Chunk 4 ---\n",
      "EDUCACIÓN: \n",
      "Posgrado en Inteligencia Artiﬁcial   \n",
      "Universidad de Buenos Aires   \n",
      "2024 - Actualidad  \n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Uso del proceso completo\n",
    "# ===========================\n",
    "pdf_path = \"CV LARA ROSENBERG.pdf\"\n",
    "\n",
    "# Extraer todo el texto del PDF\n",
    "full_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Crear un objeto Document con el texto completo y metadata\n",
    "doc = create_document(full_text, metadata={\"source\": pdf_path})\n",
    "\n",
    "# Dividir el texto en chunks \n",
    "chunks = chunk_text(doc)\n",
    "\n",
    "# Mostrar algunos ejemplos de los chunks generados\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(chunk.page_content[:100])  # Muestra los primeros 100 caracteres del chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3030be73-e23c-4ce8-8c86-5cfef00c5c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Obtenemos los embeddings con modelo local\n",
    "# ===========================\n",
    "\n",
    "# Cargar modelo de embeddings local\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  \n",
    "\n",
    "# Función para obtener embedding usando modelo local\n",
    "def get_embedding(text):\n",
    "    return embedding_model.encode(text).tolist()\n",
    "\n",
    "# Crear lista de textos desde los chunks\n",
    "text_chunks = [chunk.page_content for chunk in chunks]\n",
    "\n",
    "# Crear vectores con embeddings y metadatos\n",
    "vectors = []\n",
    "for i, chunk in enumerate(text_chunks):\n",
    "    vector = {\n",
    "        \"id\": f\"chunk-{i}\",\n",
    "        \"values\": get_embedding(chunk),\n",
    "        \"metadata\": {\n",
    "            \"text\": chunk\n",
    "        }\n",
    "    }\n",
    "    vectors.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "475a9c89-d955-4bbc-83d1-153c1d6b79ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'euclidean',\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Se envian los embeddings a pinecone\n",
    "# ===========================\n",
    "\n",
    "index.upsert(vectors=vectors)\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea07c494-62ad-44a8-9a46-16b91f7639bd",
   "metadata": {},
   "source": [
    "# CV CLAUDIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "202d502a-ea4a-43cf-88f0-6d46599abe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_INDEX = \"cv-claudio-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f443b650-4f4c-4eb2-88fc-33db1d0947df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Configuración del índice en Pinecone\n",
    "# ===========================\n",
    "\n",
    "# Verificar si el índice existe; si no, crearlo\n",
    "if PINECONE_INDEX not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=PINECONE_INDEX,\n",
    "        dimension=384,  # Dimensión de los vectores (se define por el modelo utilizado para generar embeddings)\n",
    "        metric='euclidean',  # Métrica para comparación\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',  \n",
    "            region='us-east-1'  \n",
    "        )\n",
    "    )\n",
    "\n",
    "# Conectar al índice\n",
    "index = pc.Index(PINECONE_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2e265fa-13cc-4b71-9429-0044b78ed262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Función para extraer texto de PDF usando 'fitz'\n",
    "# ===========================\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cb3fdcd-753e-4ff2-b111-ef5a667bc14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Función para obtener embeddings usando OpenAI\n",
    "# ===========================\n",
    "def get_embedding(texto):\n",
    "    response = client.embeddings.create(\n",
    "        input=[texto],\n",
    "        model=\"text-embedding-3-small\"  # Modelo de embedding (puede variar)\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9854fa1-ad29-4cc5-9761-9333ba9237e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Función para cargar y extraer texto de PDF con 'pdfminer'\n",
    "# ===========================\n",
    "def extract_text_from_pdf(file_path):\n",
    "    return extract_text(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb8e9611-9da7-4bce-8f79-e976f5b06547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Función para crear un objeto Document de LangChain\n",
    "# ===========================\n",
    "def create_document(text, metadata=None):\n",
    "    if metadata is None:\n",
    "        metadata = {}\n",
    "    return Document(page_content=text, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12e0c0a5-22d2-4fd8-9b52-d9a78d73dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Función para dividir texto en chunks\n",
    "# ===========================\n",
    "def chunk_text(document, chunk_size=1000, chunk_overlap=200):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return splitter.split_documents([document])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "246024f3-8226-446d-a459-30337758ba56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "CLAUDIO BARRIL \n",
      "\n",
      "INGENIERO DE SOFTWARE \n",
      "\n",
      "Camargo 914, CABA, Argentina \n",
      "\n",
      "claudiobarril@gmail.com \n",
      "\n",
      "+5\n",
      "\n",
      "--- Chunk 2 ---\n",
      "■  Desarrollo de aplicaciones usando JavaScript, NodeJS, TypeScript y \n",
      "\n",
      "React. \n",
      "\n",
      "■  Experiencia en l\n",
      "\n",
      "--- Chunk 3 ---\n",
      "técnicas. \n",
      "\n",
      "●  Mercado Libre \n",
      "\n",
      "○  Marzo 2019-Marzo 2020 \n",
      "\n",
      "\f",
      "○ \n",
      "\n",
      "Ingeniero de Software Senior \n",
      "\n",
      "■  Des\n",
      "\n",
      "--- Chunk 4 ---\n",
      "■  Estimación de esfuerzos y diseño técnico de soluciones. \n",
      "■ \n",
      "\n",
      "Instalación y mantenimiento de las i\n",
      "\n",
      "--- Chunk 5 ---\n",
      "HABILIDADES TÉCNICAS \n",
      "\n",
      "●  Lenguajes de Programación: Java, NodeJS, TypeScript, JavaScript, React, \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Uso del proceso completo\n",
    "# ===========================\n",
    "\n",
    "pdf_path = \"Claudio Barril CV.pdf\"\n",
    "\n",
    "# Extraer todo el texto del PDF\n",
    "full_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Crear un objeto Document con el texto completo y metadata\n",
    "doc = create_document(full_text, metadata={\"source\": pdf_path})\n",
    "\n",
    "# Dividir el texto en chunks \n",
    "chunks = chunk_text(doc)\n",
    "\n",
    "# Mostrar algunos ejemplos de los chunks generados\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(chunk.page_content[:100])  # Muestra los primeros 100 caracteres del chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dedb1b1-e77f-493a-8faa-fa081b01aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Obtenemos los embeddings con modelo local\n",
    "# ===========================\n",
    "\n",
    "# Cargar modelo de embeddings local\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  \n",
    "\n",
    "# Función para obtener embedding usando modelo local\n",
    "def get_embedding(text):\n",
    "    return embedding_model.encode(text).tolist()\n",
    "\n",
    "# Crear lista de textos desde los chunks\n",
    "text_chunks = [chunk.page_content for chunk in chunks]\n",
    "\n",
    "# Crear vectores con embeddings y metadatos\n",
    "vectors = []\n",
    "for i, chunk in enumerate(text_chunks):\n",
    "    vector = {\n",
    "        \"id\": f\"chunk-{i}\",\n",
    "        \"values\": get_embedding(chunk),\n",
    "        \"metadata\": {\n",
    "            \"text\": chunk\n",
    "        }\n",
    "    }\n",
    "    vectors.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afd0fea3-60aa-4549-b9f3-ac0c46c25aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'euclidean',\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Se envian los embeddings a pinecone\n",
    "# ===========================\n",
    "\n",
    "index.upsert(vectors=vectors)\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cfe445-e6de-43c9-a413-3db56e0cad0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
